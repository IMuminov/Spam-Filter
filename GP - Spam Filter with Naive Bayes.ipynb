{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Filter Using Probability theory\n",
    "\n",
    "This project is about building an SMS Spam filter algorithm. The algorithm will be developed based on Naive Bayes theorem. What it essentially does is that it uses a dataset containing sms messages that are flagged as spam or non-spam and learns from that. Based on the knowledge built on the data, the algorithm will classify new messages whether they are spam or ham.\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can also download the dataset directly [from this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 2), Label    0\n",
       " SMS      0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the necessary modules and loading the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "messages = pd.read_csv('data/SMSSpamCollection.csv', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "messages.shape, messages.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set contains 2 columns and 5572 rows, and it has no NA values, which means no need for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(messages['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **87%** of messages are non-spam, and **13%** is flagged as spam. These are prior probabilities that will be useful in our calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the dataset into train and test\n",
    "\n",
    "It is important to think of testing the algorithm before we go about creating it. A good idea is to split the data into *train and test* so that:\n",
    "- Train dataset will be used to train the model\n",
    "- test will be used to test how good our model actually is.\n",
    "\n",
    "For Training we will use **80% ~4,458 messages** of the data, and the rest **20% ~1,114 messages** will be for testing.\n",
    "\n",
    "### Our final goal. \n",
    "\n",
    "Our goal is to achieve 80%+ accuracy with our model. \n",
    "\n",
    "We will split the data into two parts, but before, we will randomize the dataset so that our spam and ham messages are spread across the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizing the dataset before we split. \n",
    "messages = messages.sample(frac=1, random_state=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4458, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing display module for displaying several tables/graphs\n",
    "import IPython.display\n",
    "\n",
    "#seperating train 80%, and test 20%\n",
    "train = messages.iloc[:4458, :]\n",
    "test = messages.iloc[4458:, :]\n",
    "\n",
    "display(round(test['Label'].value_counts(normalize=True)*100), test.shape) \n",
    "display(round(train['Label'].value_counts(normalize=True)*100), train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully split the datasets, and the resulting datasets have **exact proportion** of spam/ham messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Algorithm on *train* dataset\n",
    "\n",
    "### Data cleaning.\n",
    "\n",
    "Before we start building our algorithm we need to clean our data for easier calculation. \n",
    "Here are the things important for our model:\n",
    "- A vocabulary: consists all the unique words in our entire train data\n",
    "- number of unique words in each message\n",
    "\n",
    "In order to get the # of unique words in each message, we will create columns that represent each unique word, and each row will show how many times each words was repeated in each message.\n",
    "\n",
    "First, we need to remove the punctutation from all messages, as we don't need them for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation from messages. \n",
    "#re.sub('\\W', ' ', 'Message') This is our regex for replacing any upper/lowercase \n",
    "#character that is not a letter, digits.\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "train['SMS'] = train['SMS'].str.replace(r'\\W', ' ')\n",
    "train['SMS'] = train['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have removed the punctutation and made all letters lowercase. \n",
    "\n",
    "Now it is time to transform our dataset with cols each representing unique word in our vocabulary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a vocabulary containing all unique words from all messages.\n",
    "vocabulary = []\n",
    "\n",
    "for sms in train['SMS'].str.split():\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple operation of converting messages to a list of words, and transforming a list into set to remove duplicates and back to list - gave us a list of unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the train dataset into word count of each unique word for each sms/row\n",
    "\n",
    "The below code will help create a frequency dictionary of each row in our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a dictionary of words with word count for each SMS.\n",
    "word_counts_per_sms = {unique_word: [0] * (len(train['SMS'])) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train['SMS'].str.split()):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming dictionary to a dataframe.\n",
    "final_training = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a frequency of each word for every message in our train dataset, In order to better see the data, we will combine this new dataframe with our existing train dataset. The resulting dataset will be called **final_training_set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenating the train and final_training datasets.\n",
    "dfs = [train, final_training]\n",
    "final_training_set = pd.concat(dfs, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the algorithm\n",
    "\n",
    "Now that we have our training dataset ready, we can start building our model based on Multinomial Naive Bayes Theorem. \n",
    "\n",
    "The formula for Multinomial Naive Bayes Algorithm is the following. \n",
    "\n",
    "![P(Spam|Words)](img/p_spam_given_words.png)\n",
    "![P(Ham|Words)](img/p_ham_given_words.png)\n",
    "\n",
    "We will be comparing the result of the first formula to the second, and \n",
    "- **if P(Spam|Words) > P(Ham|Words)**, the message will be marked **spam**\n",
    "- **if P(Spam|Words) < P(Ham|Words)**, the message will be marked **ham**\n",
    "- **if P(Spam|Words) < P(Ham|Words)**, we will need **human judgement** for these messages, as the algorithm could not classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding probabilities of spam and ham messages\n",
    "p_ham_spam = round(final_training_set['Label'].value_counts(normalize=True),2)\n",
    "p_ham = p_ham_spam['ham']\n",
    "p_spam = p_ham_spam['spam']\n",
    "\n",
    "\n",
    "#seperating ham and spam messages\n",
    "ham_messages = final_training_set.loc[final_training_set['Label']=='ham', 'SMS']\n",
    "spam_messages = final_training_set.loc[final_training_set['Label']=='spam', 'SMS']\n",
    "\n",
    "\n",
    "#counting number of words for ham and spam messages seperately\n",
    "n_ham = 0\n",
    "n_spam = 0\n",
    "\n",
    "\n",
    "for message in ham_messages:\n",
    "    message = str(message)\n",
    "    message = message.split()\n",
    "    n_ham += len(message)\n",
    "\n",
    "for message in spam_messages:\n",
    "    message = str(message)\n",
    "    message = message.split()\n",
    "    n_spam += len(message)\n",
    "    \n",
    "# Lapllace smoothing with a = 1\n",
    "a = 1\n",
    "\n",
    "\n",
    "# number of words in vocabulary\n",
    "n_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we calculated constants that will be used in our model. Now we will calculate two important probabilities.\n",
    "\n",
    "- **P of a word given spam message**\n",
    "- **P of a word given ham message**\n",
    "\n",
    "Here is the formula for calculating these values for each word.\n",
    "\n",
    "![p_words_given_ham_spam](img/p_words_given_ham_spam.png)\n",
    "\n",
    "- **N(w|spam)** - total number that the word appears in spam messages\n",
    "- **N(w|ham)** - total number that the word appears in ham messages\n",
    "- **N(spam)** - total number of words in spam messages\n",
    "- **N(ham)** - total number of words in ham messages\n",
    "- **a** - is alpha for Laplace smoothing\n",
    "\n",
    "[Laplace/additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) is a technique used to avoid having 0 probabilities, as some words might have appearances in either of the categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create two dictionaries to store probabilities for each type of message\n",
    "p_word_given_spam = {unique_word:0 for unique_word in vocabulary} \n",
    "p_word_given_ham = {unique_word:0 for unique_word in vocabulary} \n",
    "\n",
    "\n",
    "# we will create a counter of each type of word using collections.Counter object\n",
    "import collections\n",
    "\n",
    "\n",
    "spam_words = []\n",
    "ham_words = []\n",
    "for message in ham_messages.str.split():\n",
    "    for word in message:\n",
    "        ham_words.append(word)\n",
    "for message in spam_messages.str.split():\n",
    "    for word in message:\n",
    "        spam_words.append(word)\n",
    "     \n",
    "    \n",
    "# Now that we have a list of all spam/ham words, we will create a dictionary of their count. \n",
    "ham_word_count = collections.Counter(ham_words)\n",
    "spam_word_count = collections.Counter(spam_words)\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_ham_word = ham_word_count[word]\n",
    "    n_spam_word = spam_word_count[word]\n",
    "    \n",
    "    p_word_given_spam[word] = (n_spam_word + a) / (n_spam + a * n_vocabulary)\n",
    "    p_word_given_ham[word] = (n_ham_word + a) / (n_ham + a * n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a new Message\n",
    "\n",
    "We are ready to write our final algorithm and function that classifies a new message as spam or ham.\n",
    "\n",
    "The function will take a string as an input and formats it as necessary. After having a message in a desired fashion, the function will calculate the probabilities for both spam and ham, after that classify the message depending on the probability results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    \n",
    "    # calculation of probabilities for spam and ham\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    \n",
    "    #iterate\n",
    "    for word in message:\n",
    "        if word in p_word_given_spam:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "        if word in p_word_given_ham:\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "    \n",
    "\n",
    "    #classification based on comparison results\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the classify function, now we will apply this on two custom messages, Note that these messages are deliberately made easy as spam or ham only for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spam', 'ham')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "message_2 = \"Sounds good, Tom, then see u there\"\n",
    "classify(message_1), classify(message_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our function on test data.\n",
    "\n",
    "So now we have the algorithm ready to go with our test dataset. Test dataset has never been applied to our algorithm, so it is a new message with respect to algorithm perspective. \n",
    "\n",
    "We will create a new col in test dataset called **'predicted'** that will store results of our function output. After that we will be able to compare our predictions with our actual human classified labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying our function to our test dataset\n",
    "test['predicted'] = test['SMS'].apply(classify)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking accuracy of our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.74"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check the accuracy of our model. \n",
    "correct = 0\n",
    "total = len(test.SMS)\n",
    "\n",
    "for row in test.iterrows():\n",
    "    label = row[1][0]\n",
    "    predicted = row[1][2]\n",
    "    if label == predicted:\n",
    "        correct += 1\n",
    "accuracy = round((correct / total) * 100, 2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result\n",
    "\n",
    "Our model is predicting the message with 98.74% accuracy, which is much higher than I expected. This was a fun project to work with, thank you. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
